{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b17395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "from math import hypot \n",
    "import numpy as np\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8fccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pycaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b60a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Model \n",
    "mpHands = mp.solutions.hands \n",
    "hands = mpHands.Hands( \n",
    "    static_image_mode=False, \n",
    "    model_complexity=1, \n",
    "    min_detection_confidence=0.75, \n",
    "    min_tracking_confidence=0.75, \n",
    "    max_num_hands=2) \n",
    "  \n",
    "Draw = mp.solutions.drawing_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614bf5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6836e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "volRange = volume.GetVolumeRange()\n",
    "minVol , maxVol , volBar, volPer= volRange[0] , volRange[1], 400,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start capturing video from webcam \n",
    "cap = cv2.VideoCapture(0) \n",
    "  \n",
    "while True: \n",
    "    # Read video frame by frame \n",
    "    _, frame = cap.read() \n",
    "  \n",
    "    # Flip image \n",
    "    frame = cv2.flip(frame, 1) \n",
    "  \n",
    "    # Convert BGR image to RGB image \n",
    "    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "  \n",
    "    # Process the RGB image \n",
    "    Process = hands.process(frameRGB) \n",
    "  \n",
    "    landmarkList = [] \n",
    "    # if hands are present in image(frame) \n",
    "    if Process.multi_hand_landmarks: \n",
    "        # detect handmarks \n",
    "        for handlm in Process.multi_hand_landmarks: \n",
    "            for _id, landmarks in enumerate(handlm.landmark): \n",
    "                # store height and width of image \n",
    "                height, width, color_channels = frame.shape \n",
    "  \n",
    "                # calculate and append x, y coordinates \n",
    "                # of handmarks from image(frame) to lmList \n",
    "                x, y = int(landmarks.x*width), int(landmarks.y*height) \n",
    "                landmarkList.append([_id, x, y]) \n",
    "  \n",
    "            # draw Landmarks \n",
    "            Draw.draw_landmarks(frame, handlm, \n",
    "                                mpHands.HAND_CONNECTIONS) \n",
    "  \n",
    "    # If landmarks list is not empty \n",
    "    if landmarkList != []: \n",
    "        # store x,y coordinates of (tip of) thumb \n",
    "        x_1, y_1 = landmarkList[4][1], landmarkList[4][2] \n",
    "  \n",
    "        # store x,y coordinates of (tip of) index finger \n",
    "        x_2, y_2 = landmarkList[8][1], landmarkList[8][2] \n",
    "  \n",
    "        # draw circle on thumb and index finger tip \n",
    "        cv2.circle(frame, (x_1, y_1), 7, (0, 255, 0), cv2.FILLED) \n",
    "        cv2.circle(frame, (x_2, y_2), 7, (0, 255, 0), cv2.FILLED) \n",
    "  \n",
    "        # draw line from tip of thumb to tip of index finger \n",
    "        cv2.line(frame, (x_1, y_1), (x_2, y_2), (0, 255, 0), 3) \n",
    "  \n",
    "        # calculate square root of the sum of \n",
    "        # squares of the specified arguments. \n",
    "        L = hypot(x_2-x_1, y_2-y_1) \n",
    "        \n",
    "        vol = np.interp(L, [50, 220], [minVol, maxVol])\n",
    "\n",
    "        volume.SetMasterVolumeLevel(vol, None)\n",
    "        volBar = np.interp(L, [50, 220], [1000, 500])\n",
    "        volPer = np.interp(L, [50, 220], [0, 500])\n",
    "        \n",
    "        cv2.imshow('Image', frame) \n",
    "        if cv2.waitKey(1) & 0xff == ord('q'): \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef5fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
